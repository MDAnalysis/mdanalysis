# -*- Mode: python; tab-width: 4; indent-tabs-mode:nil; coding:utf-8 -*-
# vim: tabstop=4 expandtab shiftwidth=4 softtabstop=4 
#
# MDAnalysis --- http://www.MDAnalysis.org
# Copyright (c) 2006-2015 Naveen Michaud-Agrawal, Elizabeth J. Denning, Oliver
# Beckstein and contributors (see AUTHORS for the full list)
#
# Released under the GNU Public Licence, v2 or any higher version
#
# Please cite your use of MDAnalysis in published work:
#
# N. Michaud-Agrawal, E. J. Denning, T. B. Woolf, and O. Beckstein.
# MDAnalysis: A Toolkit for the Analysis of Molecular Dynamics Simulations.
# J. Comput. Chem. 32 (2011), 2319--2327, doi:10.1002/jcc.21787
#

from six.moves import range
import numpy as np
import warnings
import os
import shutil
from subprocess import check_output

import datreant.core as dtr

## TODO - args still a bit over the place

## TODO - NAMING. Currently named in line with docs for Grossfield wham, but
## some of these aren't very clear/nice so likely to change...
def wham(bundle, data_names=None, timeseries_type=None, 
         calc_temperature=None, hist_max=None, hist_min=None,
         start_time=None, end_time=None, run_bootstrap=True, 
         energy_units_in=None, energy_units_out=None, 
         keep_files=False, root='./WHAM_TEMP', **wham_args):
    """ Wrapper for the Grossfield implementation of WHAM.

    [link documentation]

    Each simulation must have the appropriate metadata (spring constant,
    restrained value, temperature) and auxiliary data (timeseries data as
    either reaction coordinate value, difference from restrained value, or
    value of the restraining force); if names differ from the defaults they
    must be specified in ``data_names``. If using MC bootstrap error analysis,
    can also specify a correlation time for each window. If simulations were
    performed at different temperatures, a potential energy auxiliary must also
    be provided in ``data_names``.

    [[ Various wham paramaters; examples; TBA... ]]


    Parameters
    ----------
    bundle : datreant Bundle
        Bundle of the simulations WHAM is to be performed for.
    data_names : dict, optional
        Dictionary of the names of the auxiliary/metadata, if not defaults;
        see :func:`check_names` for names and defaults.
    timeseries_type : str, optional
        What value is recorded in timeseries_data; for available options and 
        default behaviour see :func:`calc_reaction_coord`.
    calc_temperature : float, optional
        Temperature at which to perform wham calculation (in Kelvin). Must be
        specified if simulations are perfored at different temperatures; 
        otherwise the common simulation temperature is used.
    hist_min, hist_max : float, optional
        Min/max values of reaction coordinate to use in calculation. If None 
        (default), will set to the lowest/highest value of the reaction 
        coordinate across all simulations.
    start_time, end_time : float, optional
        Start/end time (in ps) to use when calculating profile; data outside
        of this time range will be ignored.
    run_boostrap : bool, optional
        Whether to run Monte Carlo bootstrap error analysis.
    **wham_args
        Other arguments to pass to run_grossfield_wham

    Returns
    -------
    profile : Numpy ndarray
        The PMF profile calculated by WHAM, as a (n_bins, 3) array with 
        reaction coordinate values in the first column, energy value in the 
        second (with units ``energy_units``) and error in the third (if 
        bootstrap error estimation is turned off with ``run_bootstrap``, this
        third column will contain only zeros).

    Other parameters
    ----------------
    energy_units : str, optional
        [[ Free energy units to use: kcal, kJ, ...]]
    keep_files : bool, optional
        [[ Whether to keep files generated by wham ]]
    file_root : str
        [[ Name for folder in which to write input/outfiles from WHAM; will be
        removed unless ``keep_files`` is True. ]]
    """
    # check all our auxiliary/metadata are present...
    data_names = check_names(bundle, **(data_names or {}))

    # check if simulations have different temperatures...
    if not _check_multi_temp(bundle, data_names['temperature'], calc_temperature):
        # set energy to None if not already to flag as single-temperature
        data_names['energy'] = None
        calc_temperature = bundle.categories[data_names['temperature']][0]
    elif data_names['energy'] is None:
        raise TypeError("Auxiliary containing energy values must be provided if"
                        " simulations were performed at different temperatures")

    # check our reaction coord type option...
    calc_reaction_coord(timeseries_type)

    # check start/end time values...
    _check_min_max(start_time, "start time", end_time, "end_time")

    # check our energy unit options...
    convert_energy(unitin=energy_units_in, unitout=energy_units_out)
    energy_units_wham = 'kcal'
    ## TODO - we still need to know if wham is configured for kcal or kj - 
    ## check this from the file, or require as user input?

    # set up files...
    try:
        os.makedirs(root)
    except OSError:
        ## TODO - do we want an option to overwrite folder if it does exist?
        raise ValueError("Folder {} already exists".format(root))
    meta_fname = root+'/metadatafile.dat'
    data_fname = './timeseries_{}.dat' # assuming they're in the same dir as meta
    out_fname = root+'/output.dat'

    # check all our wham parameters are valid before we start writing files
    run_grossfield_wham(check_only=True, calc_temperature=calc_temperature,
                        hist_max=hist_max, hist_min=hist_min, 
                        outfile=out_fname, metafile=meta_fname, **wham_args)

    # write input files
    min_max = write_grossfield_input(bundle, data_names=data_names, 
                                     filename=meta_fname, data_fname=data_fname,
                                     hist_max=hist_max, hist_min=hist_min, 
                                     start_time=start_time, end_time=end_time,
                                     timeseries_type=timeseries_type, 
                                     ener_units=energy_units_in, 
                                     wham_units=energy_units_wham,
                                     checked=True)

    # set our hist min/max values if not specified in args
    hist_min = min_max[0] if hist_min is None else hist_min
    hist_max = min_max[1] if hist_max is None else hist_max

    # run!
    run_grossfield_wham(calc_temperature=calc_temperature, hist_max=hist_max, 
                        hist_min=hist_min, metafile=meta_fname,
                        outfile=out_fname, run_bootstrap=run_bootstrap, 
                        **wham_args)
    # read the output    
    profile = read_grossfield_output(out_fname, ener_units=energy_units_out,
                                     wham_units=energy_units_wham,
                                     temperature=calc_temperature)

    # clear our files
    if not keep_files:
        # TODO - make sure we're not removing anything important. 
        # Do another way - keep a record of files we wrote instead?
        shutil.rmtree(root)

    return profile
    # TODO - in the outfile we also get the probability + it's error in [:,3] 
    # and [:,4]; and the 'F-values' for each simulation (that we didn't skip);
    # option to get prob instead of PMF? option to return Fvalues as well (tuple?)


def check_names(bundle, spring='spring', loc_win_min='loc_win_min', 
         temperature='temperature', correl_time=None, 
         timeseries_data='timeseries_data', energy=None,
         ):
    """ Check *bundle* contains the appropriate metadata/auxiliaries for WHAM.

    In simplest use, each simulation in the bundle must have *spring*, 
    *loc_win_min* and *temperature* metadata, and a *timeseries_data* auxiliary.
    If simulations are performed at different temperatures, an *energy* 
    auxiliary is also required. If bootstrap error analysis is to be used,
    a *correl_time* metadata may also be specified.

    Parameters
    ----------
    bundle : datreant Bundle
        Bundle of simulations
    spring : str
        Name of metadata storing the spring constant that each simulation uses,
        assuming biasing potential has form 1/2 k(x-x0)^2. [[ <--format ]]
        [[ Some simulation packages don't use the 1/2 - so have to pass 2*the 
        restraint const instead? ]].
        Must match the units used for energy + the reaction coordinate. [examples?].
    loc_win_min : str
        Name of metadata field storing the reaction coordinate value that is
        the minimum of the biasing potential in each window, ie x0 above.
    temperature : str
        Name of metadata field storing each window's temperature (in Kelvin)
    correl_time : str, optional
        Name of metadata field storing decorrelation time for each window, in 
        time step units. Only used for boostrap error; will be set to 1 for 
        each window if not provided.
    timeseries_data : str
        Name of the auxiliary containing the force/reaction coordinate value 
        throughout simulation.
    energy : str, optional
        Name of the auxiliary containing potential energy. [Currently must be
        at exactly the same same steps as timeseries above (ie same dt and 
        initial time)]. [I assume units must match energy_units?]. Only
        required if simulations performed at different temperatures.

    Returns
    -------
    data_names : dict
        Dictionary containing the set if auxiliary/metadata names for *bundle*.
    """
    if not isinstance(bundle, dtr.Bundle):
        TypeError('{} is not a bundle'.format(bundle))
    check_bundle_metadata(bundle, [spring, loc_win_min, temperature])
    if correl_time:
        check_bundle_metadata(bundle, correl_time)
    check_bundle_auxiliaries(bundle, [timeseries_data])
    if energy:
        check_bundle_auxiliaries(bundle, [energy])
    data_names = locals()
    data_names.pop('bundle')
    return data_names


def run_grossfield_wham(periodicity='', hist_min=None, 
                        hist_max=None, num_bins=200, tol=1e-6, 
                        calc_temperature=None, numpad=0, metafile=None, 
                        outfile=None, num_MC_trials=200, check_only=False, 
                        run_bootstrap=True):
    """
    Check the arguments for running WHAM w/ Grossfield implementation,
    then run command.

    [[ ARGS NEED SORTING ]]

    Parameters
    ----------
    perodicity : str, optional
        Periodicity of system. Default ('') indicates a nonperiodic reaction
        coordiante.
    num_bins : int, optional
        Number of bins to use in histogram (= number of points in final profile).
    tol : float, optional
        Reference value to assess convergence (will stop iteration when the 
        biggest change in F-value is less than this).
    numpad : int, optional
        ['padding' values, for periodic PMFs; for nonperiodic use 0 (default)]
    num_MC_trials : int, optional
        Number of 'fake' data sets to create, if running bootstrap error analysis
    metafile : str
        [[ filename for writting metadata file ]]
    outfile : str
        [[ filename for writting final output ]]
    check_only : bool
        [[ (Default False). If True, only check values are valid; exit before 
         running wham command ]]
    calc_temperature, hist_min, hist_max, run_bootstrap
        [[ TBA?, see wham above ]]
    """
    wham_args = locals()
    ## TODO - need to provide path to runfile? where best to do this? (check
    ## it's actually wham...)
    wham_command = '~/wham/wham/wham'

    # check everything here to catch issues before launching the command (and
    # so we don't run something we don't want...)
    _check_min_max(hist_min, 'hist_min', hist_max, 'hist_max')
    _check_number(num_bins, 'number of bins', positive=True, integer=True)
    _check_number(tol, 'tolerance', positive=True)
    _check_number(calc_temperature, 'calculation temperature', positive=True)
    _check_number(numpad, 'numpad', integer=True)
    _check_number(num_MC_trials, 'num_MC_trials', positive=True, integer=True)
    if periodicity not in ['', 'P', 'Ppi']: # OR 'P<val>'!
        raise ValueError('Periodicity not valid...') ###
        ## TODO - pass as something else? + Sort out P<val>
    ## TODO - check files?

    if not check_only:
        # we should have a value for all args to run...
        for key, item in wham_args.items():
            if item is None:
                raise TypeError("Must provide {}".format(key))
        run_command = [wham_command, periodicity, hist_min, hist_max, num_bins, 
                       tol, calc_temperature, numpad, metafile, outfile]
        randSeed = 1 # TODO - how to deal with random seed - should make an argument?
        if run_bootstrap:
            run_command = run_command+[num_MC_trials, randSeed]
        check_output(list_to_string(run_command), shell=True)
        ## TODO - switch to subprocess; [+ catch any errors etc]



def write_grossfield_input(bundle, filename='metadatafile.dat', 
                           data_fname='timeseries_{}.dat', 
                           data_names=None, ener_units=None, wham_units=None,
                           checked=False, **kwargs):
    """
    [[ Write the appropriate metafile + timeseries files to run Grossfield wham
    implementation on *bundle*.

    Returns the min and max reaction coordinate values, set to the lowest/highest
    value in the timeseries data if not set in args. ]]

    [[ ARGS NEED SORTING ]]

    Parameters
    ----------
    bundle
    metafile_name
    timeseriesfile_name
    data_names
    checked
    **kwargs
        To be passed onto write_timeseries_file

    """
    if not checked:
        data_names = check_names(bundle, **(data_names or {}))

    # TODO - check metafile/timeseries are valid here?
    with open(filename, 'w') as metafile:
        global_min_max = (None, None)
        inrange_sims=[] # keep track of which simulations we actually feed through
                        # to wham (so we don't try run with none...)
        for sim in bundle:
            datafile = data_fname.format(sim.name)
            try:
                min_max = write_timeseries_file(sim, filename=datafile, 
                                                data_names=data_names, 
                                                ener_units=ener_units,
                                                wham_units=wham_units,
                                                checked=True, **kwargs)

            except ValueError as err:
                continue
            # write to metafile
            if data_names['correl_time']:
                correl = sim.categories[data_names['correl_time']]
            else:
                # only used if doing bootstrap but need as a placeholder if
                # specifying temperatures; this seems to be the default
                # value used in wham so should be fine here too
                correl = 1
            k_user_units = sim.categories[data_names['spring']]
            k_wham_units = convert_energy(k_user_units, unitin=ener_units,
                                          unitout=wham_units)
            x0 = sim.categories[data_names['loc_win_min']]
            metafile_info = [datafile, x0, k_wham_units, correl]
            if data_names['energy']:
                metafile_info.append(sim.categories[temperature])
            metafile.write(list_to_string(metafile_info)+'\n')
            inrange_sims.append(sim.name)
            global_min_max = update_min_max(min_max, global_min_max)

        if len(inrange_sims) == 0:
            raise ValueError('Aborting (all simulations skipped). Try '
                             'increasing time or reaction coordinate range.')
    return global_min_max

 

def write_timeseries_file(sim, filename='timeseries.dat', data_names=None, 
                          start_time=None, end_time=None, hist_min=None,
                          hist_max=None, timeseries_type=None, checked=False,
                          ener_units=None, wham_units=None):
    """
    Write a Grossfield-WHAM 'timeseries file' for the simulation *sim*

    Parameters
    ----------
    sim : mdsynthesis.Sim object
        Simulation to write a 'timeseries file' for
    filename : str
        Filename for timeseries file; defaults to 'timeseries.dat'
    data_names : dict, optional
        dictionary containing names for the relevant metadata/auxiliaries in 
        *sim*
    start_time, end_time: float, optional
        Start/end time 
    dataseries_type : 
    checked :
    hist_min, hist_max : float


    Return
    ------
    (min, max)
        Tuple with minimum and maximum values of the reaction coordinate
        between *start_time* and *end_time*

    Raises
    ------
    ValueError
        If no datapoints are within the time range *start_time* to *end_time*.

    Note
    ----
    In the case energies are needed, currently assumes 'timeseries data' and
    energies steps coincide.
    """
    if not checked:
        data_names = check_names(dtr.Bundle(sim), **(data_names or {}))
    start, end = _get_start_end_step(sim, data_names['timeseries_data'], 
                                     start_time, end_time)
    # check we've ended up with a valid slice

    if start == end:
        raise ValueError(_outofrange_msg('time', sim.name, 
                                         (start_time, end_time)))
    k = sim.categories[data_names['spring']]
    x0 = sim.categories[data_names['loc_win_min']]
    min_max = (None, None)
    with open(filename, 'w') as timeseriesfile:
        traj = sim.universe.trajectory
        if data_names['energy']:
            ## TODO - find a way to do this as we're looping timeseries so we're 
            ## not storing this big list?
            energies = [i.data[0] for i in traj.iter_auxiliary(energy, 
                                                         start=start, stop=end)]
        timeseries_iter = traj.iter_auxiliary(data_names['timeseries_data'], 
                                              start=start, stop=end)
        for i, auxstep in enumerate(timeseries_iter):
            x = calc_reaction_coord(timeseries_type, auxstep.data[0], k=k, x0=x0)
            min_max = update_min_max((x, x), min_max)
            line = [auxstep.time, x]
            if data_names['energy']:
                ener_wham_units=convert_energy(energies[i], unitin=ener_unit,
                                               unitout=wham_unit)
                line.append(ener_wham_units)
            timeseriesfile.write(list_to_string(line)+'\n')
    if (hist_min is not None and hist_min > min_max[0] or
        hist_max is not None and hist_max < min_max[1]):
        raise ValueError(_outofrange_msg('reaction coordinate', sim.name,
                                         (hist_min, hist_max), min_max))
    return min_max


def _outofrange_msg(type, sim_name, w_range, s_range=None):
    w_start = w_range[0] if w_range[0] is not None else '_'
    w_end = w_range[1] if w_range[1] is not None else '_'
    if s_range is None:
       sim_range = '({}-{})'.format(s_start, s_end)
    else:
       sim_range = ''
    return ("No points from simulation {} {} are within WHAM {} range ({}-{}); "
           "will be skipped".format(sim_name, sim_range, type, w_start, w_end))

def read_grossfield_output(outfile, ener_units=None, wham_units=None, 
                           temperature=None):
    outfiledata = np.genfromtxt(outfile)
    time = outfiledata[:,0]
    profile = outfiledata[:,:3]
    profile[:,1:3] = convert_energy(profile[:,1:3], unitin=wham_units,
                                    unitout=ener_units, temperature=temperature)
    return profile


def calc_reaction_coord(val_type=None, value=None, k=None, x0=None):
    """ Calculate value of reaction coordinate corresponding to *value*.

    Calculate the reaction coordinate ``x`` at a particular time point from 
    *value*, depending on it's *type*. The spring constant ``k`` and the minimum 
    of the restraining potential ``x0`` may also be required (depending on 
    *type*).

    Current possible values of *type* are:
        - ``coord``: (DEFAULT) reaction coordinate value ``x``
        - ``force``: value of the restraining force ``F``; assuming a harmonic 
                     potential, ``x = -F/k + x0``
        - ``delta``: difference `delta_x`` in reaction coord value and minimum 
                     of restraining potential; ``x = delta_x + x0``

    Can be run without passing in a *value* to check that *val_type* is valid.

    Parameters
    ----------
    val_type : str, optional
        Keyword indicating what *value* represents. See above for valid options,
        descriptions and default.
    value : float, optional
        Value related to reaction coordinate obtained from simulation.
    k : float, optional
        Value of the spring constant; used if calculating from a force value.
        Assumed to match the units used in the force value.
    x0 : float, optional
        Minimum of the restraining potential along the reaction coordiante; 
        used e.g. if calculating from a force value.

    Returns
    -------
    float
        Value of the reaction coordinate 
    """
    def coord(value, k, x0):
        return value
    def delta(value, k, x0):
        if x0 is None:
            raise ValueError('Must provide x0 when using a difference-in-'
                             'reaction-coordinate value')
        return value + x0
    def force(value, k, x0):
        if x0 is None or k is None:
             raise ValueError('Must provide x0 and k when using a force value')
        return -value/k + x0

    options = {'coord': coord, 'delta': delta, 'force': force}
    default = 'coord'

    try:
        calc = options[val_type or default]
    except KeyError:
        raise ValueError("{} is not a valid timeseries data type; valid "
                         "options are: {}".format(val_type, options.keys()))
    if value is not None:
        return calc(value, k, x0)
        

def _get_start_end_step(sim, aux_name, start_time, end_time):
    """ Return the start/end step that corresponds to the range *start_time* to
    *end_time* in the auxiliary *aux_name* of the simulation *sim*.
    """
    step_to_time = sim.universe.trajectory.get_aux_attribute(aux_name, 
                                                             'step_to_time')
    n_steps = sim.universe.trajectory.get_aux_attribute(aux_name, 'n_steps')
    # default start step to first step (i.e. 0) and end step to after last step
    # (i.e. n_steps).
    start_step = 0
    end_step = n_steps
    for i in range(n_steps):
        if start_time is not None and step_to_time(i) < start_time:
            start_step = i + 1
        if end_time is not None and step_to_time(i) < end_time:
            end_step = i + 1
        else:
            break
    return start_step, end_step    

def convert_energy(value=None, unitin=None, unitout=None, temperature=-1):
    """
    """
    unit_conversions = {'kcal': 1, # kilocalorie, 1 kCal = 1 kCal
                        'kj': 0.239006, # kiloJoule, 1 kJ = 0.239006 kCal
                        'kt': -1*0.239006 # kT
                        }
    default = 'kcal'
    unitin = unitin if unitin is not None else default
    unitout = unitout if unitout is not None else unitin
    to_kJ = {}
    for unit, name in zip([unitin, unitout], ['in', 'out']):
        try:
            to_kJ[name] = unit_conversions[unit.lower()]
        except KeyError:
            raise ValueError("{} is not a valid energy unit; valid options "
                             "are {}".format(unit, conversions.keys()))
    # if we haven't passed a value, assume we're just checking the options are
    # valid
    if value is not None:
        new_val = value * to_kJ['in']/to_kJ['out']
        return new_val


def check_bundle_metadata(bundle, expected):
    """ check each simulation in bundle has the expected metadata """
    common_metadata = bundle.categories.keys()
    for meta in expected:
        if meta not in common_metadata:
            raise ValueError("Not all simulations contain metadata {}."
                             "(Common metadata: {})".format(meta, common_metadata))
        ## TODO - also check if all the values are of the expected type?


def check_bundle_auxiliaries(bundle, expected):
    """ check each simulation in bundle has expected auxiliary """
    # when auxiliaries added to mdsynthesis, this might become more direct
    for aux in expected:
        for sim in bundle:
            if aux not in sim.universe.trajectory.aux_list:
                raise ValueError("Simulation {} does not contain auxiliary data"
                                 " {}".format(sim.name, aux))
            ## TODO - also check it's got the right length/type?

def _check_multi_temp(bundle, metaname, calc_temperature):
    """
    Check if simulations in *bundle* were all performed at the same temperature
    or different temperatures. If same, raise ValueError if this disagrees with
    *calc_temperature* and set calc_temperature otherwise; if different, 
    raise TypeError if we haven't provided a *calc_temperature*.

    Returns
    -------
    bool
        Whether simulations are performed at different temperatures or not
    """
    temps = bundle.categories[metaname]
    if all(t == temps[0] for t in temps):
        # all same temperature. This'll be the temperature we calculate at
        if calc_temperature and calc_temperature != temps[0]:
            ## would there be a situation where we want them to be different?
            raise ValueError('Simulations all have temperature {} but calc_temperature '
                             '{} does not match'.format(temps[0], calc_temperature))
        return False
    else:
        # different temperatures. Will need a run temperature and a potential 
        # energy for every step
        if calc_temperature is None:
            raise TypeError('Must provide a calc_temperature if simulations are '
                            'performed at different temperatures')
        return True


def _check_number(value, name, integer=False, positive=False):
    if value is not None:
        types = (int) if integer else (int, float)
        if not isinstance(value, types) or (positive and not value > 0):
            raise TypeError("Invalid {} ({})".format(name, value))
            # TODO - be more specific here


def _check_min_max(minval, minname, maxval, maxname, positive=False,
                                                     integer=False):
    _check_number(minval, minname, positive=positive, integer=integer)
    _check_number(maxval, maxname, positive=positive, integer=integer)
    if minval is not None and maxval is not None and minval >= maxval:
        raise ValueError('{} ({}) is greater than {} ({})'
                         ''.format(minname, minval, maxname, maxval))

def list_to_string(lst):
    return ' '.join([str(i) for i in lst])

def update_min_max(new, curr):
    """
    """
    new_min = (new[0] if curr[0] is None 
              else new[0] if new[0] < curr[0] 
              else curr[0])
    new_max = (new[1] if curr[1] is None 
              else new[1] if new[1] > curr[1] 
              else curr[1])
    return (new_min, new_max)
